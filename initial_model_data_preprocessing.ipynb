{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99a8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633d7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANING\n",
    "\n",
    "#load data\n",
    "#set HHX (unique housing ID) as index\n",
    "path = 'adult19.csv'\n",
    "interviewData = pd.read_csv (path, index_col='HHX')\n",
    "\n",
    "#get columns with no NANS\n",
    "interview_noNANs = interviewData.dropna(axis=1)\n",
    "\n",
    "#remove rows with \"not ascertained\" as answer i.e. essentially missing a target\n",
    "interview_noNANs = interview_noNANs[interview_noNANs.PHQCAT_A != 8]\n",
    "\n",
    "#remove columns with irrelevant features (e.g type of record type, survey year -> all the same)\n",
    "irr_features = ['IMPINCFLG_A', 'PPSU', 'PSTRAT', 'SRVY_YR', 'ASTATNEW', 'HIKIND10_A', 'HIKIND09_A', 'HIKIND08_A', \n",
    "                'HIKIND07_A', 'HIKIND06_A', 'HIKIND05_A', 'HIKIND04_A', 'HIKIND03_A', 'HIKIND02_A', 'HIKIND01_A', \n",
    "                'HHSTAT_A', 'RECTYPE', 'WTFA_A', 'WTIA_A', 'WTIA_A']\n",
    "\n",
    "interview_noNANs = interview_noNANs.drop(columns = irr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8c3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL DATA\n",
    "\n",
    "#remove rows with missing data codes\n",
    "def remove_missing_code (df, code_list, col_name_list):\n",
    "    '''remove rows if they have a missing data code\n",
    "    df: original dataset\n",
    "    code_list: list of missing data codes\n",
    "    col_name_list: list of column names with missing data code'''\n",
    "    df_new = df.copy()\n",
    "    for col in col_name_list:\n",
    "        df_new = df_new[~df_new[col].isin(code_list)]\n",
    "    return (df_new)\n",
    "\n",
    "#remove all rows with missing code 8\n",
    "clean_num_data = interview_noNANs.copy()\n",
    "\n",
    "columns = ['PCNT18UPTC', 'PCNTLT18TC', 'PCNTKIDS_A', 'PCNTADLT_A', 'PCNTFAM_A']\n",
    "code_list = [8]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)\n",
    "    \n",
    "#remove all rows with missing code 9\n",
    "columns = ['PCNTTC']\n",
    "code_list = [9]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 7, 8, 9\n",
    "columns = ['URGNT12MTC_A', 'EMERG12MTC_A', 'NUMCAN_A'] \n",
    "code_list = [7, 8, 9]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 96, 97, 98, 99\n",
    "columns = ['HEIGHTTC_A']\n",
    "code_list = [96, 97, 98, 99]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 97, 98, 99\n",
    "columns = ['AGEP_A']\n",
    "code_list = [97, 98, 99]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 997, 998, 999\n",
    "columns = ['RATCAT_A', 'WEIGHTLBTC_A'] \n",
    "code_list = [997, 998, 999]\n",
    "\n",
    "clean_num_data = remove_missing_code(clean_num_data, code_list, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412853ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ORDINAL DATA\n",
    "\n",
    "#remove all rows with missing code 8\n",
    "clean_ord_data = clean_num_data.copy ()\n",
    "\n",
    "columns = ['GADCAT_A', 'PCNTADTWFP_A', 'FDSCAT4_A', 'FDSCAT3_A', 'GAD71_A']\n",
    "code_list = [8]\n",
    "\n",
    "clean_ord_data = remove_missing_code(clean_ord_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 9\n",
    "columns = ['BMICAT_A']\n",
    "code_list = [9]\n",
    "\n",
    "clean_ord_data = remove_missing_code(clean_ord_data, code_list, columns)\n",
    "\n",
    "#remove all rows with missing code 7, 8, 9\n",
    "columns = ['HOUYRSLIV_A', 'FDSBALANCE_A', 'FDSLAST_A', 'FDSRUNOUT_A', 'GAD77_A', 'GAD76_A', 'GAD75_A', 'GAD74_A', \n",
    "           'GAD73_A', 'GAD72_A', 'PHQ88_A', 'PHQ87_A', 'PHQ86_A', 'PHQ85_A', 'PHQ84_A', 'PHQ83_A', 'PHQ82_A', \n",
    "           'PHQ81_A', 'DEPFREQ_A', 'PAYWORRY_A', 'SOCSCLPAR_A', 'SOCERRNDS_A', 'UPPOBJCT_A', 'UPPRAISE_A', \n",
    "          'UPPSLFCR_A', 'COMDIFF_A', 'DIFF_A', 'HEARINGDF_A', 'VISIONDF_A', 'PHSTAT_A', 'COGMEMDFF_A', \n",
    "          'DIABLAST_A', 'CHOLLAST_A', 'BPLAST_A', 'LASTDR_A', 'DENPREV_A', \n",
    "           'ANXFREQ_A'] \n",
    "\n",
    "code_list = [7, 8, 9]\n",
    "\n",
    "clean_ord_data = remove_missing_code(clean_ord_data, code_list, columns)\n",
    "\n",
    "#change code to 0 to 7 to keep in monotonic order\n",
    "clean_ord_data = clean_ord_data.replace({'DIABLAST_A': 0, 'CHOLLAST_A': 0, 'BPLAST_A': 0, 'LASTDR_A': 0, 'DENPREV_A': 0}, 7)\n",
    "\n",
    "# change code 5 to 0 to keep in monotonic order\n",
    "clean_ord_data.ANXFREQ_A = clean_ord_data.ANXFREQ_A.replace(5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c527fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINARY DATA \n",
    "\n",
    "#remove all rows with missing code 7, 8, 9\n",
    "\n",
    "clean_bin_data = clean_ord_data.copy()\n",
    "\n",
    "columns = ['NOTCOV_A', 'IHS_A', 'HISP_A', 'FSNAP12M_A', 'INCINTER_A', 'INCWRKO_A', 'SCHCURENR_A', 'NATUSBORN_A', \n",
    "           'AFVET_A', 'SMOKELSEV_A', 'PIPEEV_A', 'CIGAREV_A', 'ECIGEV_A', 'SMKEV_A', 'MHTHND_A', 'MHTHDLY_A', \n",
    "           'MHTHRPY_A', 'DEPMED_A', 'ANXMED_A', 'HOMEHC12M_A', 'THERA12M_A', 'EYEEX12M_A', 'SHTPNUEV_A', \n",
    "           'SHTFLU12M_A', 'RXDG12M_A', 'RX12M_A', 'MEDNG12M_A', 'MEDDL12M_A', 'HOSPONGT_A', 'DENNG12M_A', \n",
    "           'DENDL12M_A', 'PAYBLL12M_A', 'SINCOVRX_A', 'SINCOVVS_A', 'SINCOVDE_A', 'HICOV_A', 'SOCWRKLIM_A',\n",
    "           'EQUIP_A', 'HEARAID_A', 'WEARGLSS_A', 'DEPEV_A', 'ANXEV_A', 'DEMENEV_A', 'ARTHEV_A', 'COPDEV_A', \n",
    "           'DIBEV_A', 'PREDIB_A', 'CANEV_A', 'ASEV_A', 'STREV_A', 'MIEV_A', 'ANGEV_A', 'CHDEV_A', 'CHLEV_A', \n",
    "           'HYPEV_A', 'CITZNSTP_A', 'EMPWRKLSWK_A', 'DISAB3_A', \n",
    "           'OTHGOV_A', 'OTHPUB_A', 'MILITARY_A', 'CHIP_A', 'MEDICAID_A', 'MEDICARE_A', 'PRIVATE_A'] \n",
    "code_list = [7, 8, 9]\n",
    "\n",
    "clean_bin_data = remove_missing_code(clean_bin_data, code_list, columns)\n",
    "\n",
    "#change false code to 0\n",
    "columns = ['NOTCOV_A', 'IHS_A', 'HISP_A', 'FSNAP12M_A', 'INCINTER_A', 'INCWRKO_A', 'SCHCURENR_A', 'NATUSBORN_A', \n",
    "           'AFVET_A', 'SMOKELSEV_A', 'PIPEEV_A', 'CIGAREV_A', 'ECIGEV_A', 'SMKEV_A', 'MHTHND_A', 'MHTHDLY_A', \n",
    "           'MHTHRPY_A', 'DEPMED_A', 'ANXMED_A', 'HOMEHC12M_A', 'THERA12M_A', 'EYEEX12M_A', 'SHTPNUEV_A', \n",
    "           'SHTFLU12M_A', 'RXDG12M_A', 'RX12M_A', 'MEDNG12M_A', 'MEDDL12M_A', 'HOSPONGT_A', 'DENNG12M_A', \n",
    "           'DENDL12M_A', 'PAYBLL12M_A', 'SINCOVRX_A', 'SINCOVVS_A', 'SINCOVDE_A', 'HICOV_A', 'SOCWRKLIM_A',\n",
    "           'EQUIP_A', 'HEARAID_A', 'WEARGLSS_A', 'DEPEV_A', 'ANXEV_A', 'DEMENEV_A', 'ARTHEV_A', 'COPDEV_A', \n",
    "           'DIBEV_A', 'PREDIB_A', 'CANEV_A', 'ASEV_A', 'STREV_A', 'MIEV_A', 'ANGEV_A', 'CHDEV_A', 'CHLEV_A', \n",
    "           'HYPEV_A', 'CITZNSTP_A', 'EMPWRKLSWK_A', 'DISAB3_A']\n",
    "for col in columns:\n",
    "    clean_bin_data[col] = clean_bin_data[col].replace(2, 0)\n",
    "    \n",
    "\n",
    "#change second true code to 1 and false code to 0\n",
    "columns = ['OTHGOV_A', 'OTHPUB_A', 'MILITARY_A', 'CHIP_A', 'MEDICAID_A', 'MEDICARE_A', 'PRIVATE_A'] \n",
    "for col in columns:\n",
    "    clean_bin_data[col] = clean_bin_data[col].replace(2, 1)\n",
    "    clean_bin_data[col] = clean_bin_data[col].replace(3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be25cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT DATA\n",
    "\n",
    "cols = ['HISPALLP_A', 'RACEALLP_A', 'LEGMSTAT_A', 'MARSTAT_A', 'SMKECIGST_A', 'SMKCIGST_A', 'PARSTAT_A', \n",
    "           'SAPARENTSC_A', 'HISDETP_A', 'REGION', 'SEX_A', 'HOUTENURE_A', 'MARITAL_A', 'ORIENT_A', 'USUALPL_A', \n",
    "           'AVAIL_A']\n",
    "\n",
    "#isolate data to encode as one-hot\n",
    "clean_onehot_data = clean_bin_data.loc[:, cols]\n",
    "#create object\n",
    "enc = OneHotEncoder()\n",
    "#fit encoder\n",
    "enc.fit(clean_onehot_data)\n",
    "#transform data\n",
    "clean_onehot_data = enc.transform(clean_onehot_data).toarray()\n",
    "#get name of new columns\n",
    "onehot_features = enc.get_feature_names_out(cols)\n",
    "#join with previous data \n",
    "onehot_df = pd.DataFrame(clean_onehot_data, columns = onehot_features, index = clean_bin_data.index)\n",
    "clean_bin_data.drop(columns = cols)\n",
    "clean_data = pd.concat([clean_bin_data, onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc0fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate target column\n",
    "target = clean_data.PHQCAT_A\n",
    "\n",
    "#remove target from features\n",
    "features = clean_data.drop(columns = ['PHQCAT_A'])\n",
    "\n",
    "#split into test and train \n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e027b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZATION\n",
    "\n",
    "#create object and fit to training data\n",
    "normalizer = Normalizer().fit(x_train)\n",
    "#normalize training data\n",
    "x_train_norm = normalizer.transform (x_train)\n",
    "#normalize test data using same transformer\n",
    "x_test_norm = normalizer.transform (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c89d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STORE DATA\n",
    "\n",
    "#turn back to dataframes \n",
    "train = pd.DataFrame(x_train_norm, index = x_train.index, columns = x_train.columns)\n",
    "train['PHQCAT_A'] = y_train\n",
    "\n",
    "test = pd.DataFrame(x_test_norm, index = x_test.index, columns = x_test.columns)\n",
    "test['PHQCAT_A'] = y_test\n",
    "\n",
    "#make directory \n",
    "dataDir = 'CleanData'\n",
    "if not os.path.exists(dataDir):\n",
    "    os.mkdir(dataDir)\n",
    "\n",
    "#store training data\n",
    "filepath = os.path.join(dataDir, 'train.csv')\n",
    "train.to_csv(filepath) \n",
    "\n",
    "#store testing data\n",
    "filepath = os.path.join(dataDir, 'test.csv')\n",
    "test.to_csv(filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91f79c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHX</th>\n",
       "      <th>URBRRL</th>\n",
       "      <th>RATCAT_A</th>\n",
       "      <th>INCGRP_A</th>\n",
       "      <th>INCTCFLG_A</th>\n",
       "      <th>FAMINCTC_A</th>\n",
       "      <th>HISPALLP_A</th>\n",
       "      <th>RACEALLP_A</th>\n",
       "      <th>DISAB3_A</th>\n",
       "      <th>CITZNSTP_A</th>\n",
       "      <th>...</th>\n",
       "      <th>USUALPL_A_1</th>\n",
       "      <th>USUALPL_A_2</th>\n",
       "      <th>USUALPL_A_3</th>\n",
       "      <th>USUALPL_A_7</th>\n",
       "      <th>USUALPL_A_9</th>\n",
       "      <th>AVAIL_A_1</th>\n",
       "      <th>AVAIL_A_2</th>\n",
       "      <th>AVAIL_A_3</th>\n",
       "      <th>AVAIL_A_8</th>\n",
       "      <th>PHQCAT_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H063832</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H064018</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H003505</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H013931</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H020330</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>H045242</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>H034491</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>H061542</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>H024156</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>H043605</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4854 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          HHX    URBRRL  RATCAT_A  INCGRP_A  INCTCFLG_A  FAMINCTC_A  \\\n",
       "0     H063832  0.000078  0.000272  0.000039         0.0    0.999982   \n",
       "1     H064018  0.000044  0.000118  0.000044         0.0    0.999995   \n",
       "2     H003505  0.000333  0.000222  0.000111         0.0    0.999662   \n",
       "3     H013931  0.000100  0.000267  0.000033         0.0    0.999974   \n",
       "4     H020330  0.000102  0.000153  0.000051         0.0    0.999957   \n",
       "...       ...       ...       ...       ...         ...         ...   \n",
       "4849  H045242  0.000050  0.000150  0.000050         0.0    0.999983   \n",
       "4850  H034491  0.000008  0.000108  0.000042         0.0    0.999999   \n",
       "4851  H061542  0.000115  0.000269  0.000038         0.0    0.999976   \n",
       "4852  H024156  0.000020  0.000087  0.000033         0.0    0.999999   \n",
       "4853  H043605  0.000125  0.000250  0.000031         0.0    0.999970   \n",
       "\n",
       "      HISPALLP_A  RACEALLP_A  DISAB3_A  CITZNSTP_A  ...  USUALPL_A_1  \\\n",
       "0       0.000078    0.000039       0.0    0.000039  ...     0.000039   \n",
       "1       0.000029    0.000015       0.0    0.000015  ...     0.000015   \n",
       "2       0.000222    0.000111       0.0    0.000111  ...     0.000111   \n",
       "3       0.000033    0.000267       0.0    0.000033  ...     0.000000   \n",
       "4       0.000051    0.000408       0.0    0.000051  ...     0.000051   \n",
       "...          ...         ...       ...         ...  ...          ...   \n",
       "4849    0.000075    0.000050       0.0    0.000025  ...     0.000025   \n",
       "4850    0.000025    0.000017       0.0    0.000008  ...     0.000008   \n",
       "4851    0.000154    0.000115       0.0    0.000000  ...     0.000038   \n",
       "4852    0.000013    0.000007       0.0    0.000007  ...     0.000007   \n",
       "4853    0.000062    0.000031       0.0    0.000031  ...     0.000031   \n",
       "\n",
       "      USUALPL_A_2  USUALPL_A_3  USUALPL_A_7  USUALPL_A_9  AVAIL_A_1  \\\n",
       "0        0.000000          0.0          0.0          0.0   0.000039   \n",
       "1        0.000000          0.0          0.0          0.0   0.000015   \n",
       "2        0.000000          0.0          0.0          0.0   0.000111   \n",
       "3        0.000033          0.0          0.0          0.0   0.000033   \n",
       "4        0.000000          0.0          0.0          0.0   0.000051   \n",
       "...           ...          ...          ...          ...        ...   \n",
       "4849     0.000000          0.0          0.0          0.0   0.000000   \n",
       "4850     0.000000          0.0          0.0          0.0   0.000008   \n",
       "4851     0.000000          0.0          0.0          0.0   0.000038   \n",
       "4852     0.000000          0.0          0.0          0.0   0.000007   \n",
       "4853     0.000000          0.0          0.0          0.0   0.000031   \n",
       "\n",
       "      AVAIL_A_2  AVAIL_A_3  AVAIL_A_8  PHQCAT_A  \n",
       "0           0.0   0.000000        0.0         1  \n",
       "1           0.0   0.000000        0.0         1  \n",
       "2           0.0   0.000000        0.0         1  \n",
       "3           0.0   0.000000        0.0         1  \n",
       "4           0.0   0.000000        0.0         1  \n",
       "...         ...        ...        ...       ...  \n",
       "4849        0.0   0.000025        0.0         1  \n",
       "4850        0.0   0.000000        0.0         1  \n",
       "4851        0.0   0.000000        0.0         1  \n",
       "4852        0.0   0.000000        0.0         1  \n",
       "4853        0.0   0.000000        0.0         1  \n",
       "\n",
       "[4854 rows x 231 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST TO MAKE SURE DATA CAN BE READ\n",
    "filepath = os.path.join(dataDir, 'test.csv')\n",
    "train = pd.read_csv (filepath)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544edec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningUVM",
   "language": "python",
   "name": "machinelearninguvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
