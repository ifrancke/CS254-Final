{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154d9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98586ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 505)\n",
      "(22222, 505)\n"
     ]
    }
   ],
   "source": [
    "#LOAD NONHOT DATA\n",
    "\n",
    "#training data\n",
    "dataDir = 'AnalysisData'\n",
    "dataSubDir = 'CleanDataNonhot'\n",
    "filepath = os.path.join(dataDir, dataSubDir, 'testFeaturesNonHot.csv')\n",
    "test_x_pd_nonhot = pd.read_csv (filepath, index_col = 0)\n",
    "test_x_nonhot = test_x_pd_nonhot.to_numpy()\n",
    "original_shape = test_x_pd_nonhot.shape\n",
    "print(original_shape)\n",
    "\n",
    "#testing data\n",
    "dataDir = 'AnalysisData'\n",
    "dataSubDir = 'CleanDataNonhot'\n",
    "filepath = os.path.join(dataDir, dataSubDir, 'trainFeaturesNonHot.csv')\n",
    "train_x_pd_nonhot = pd.read_csv (filepath, index_col = 0)\n",
    "train_x_nonhot = train_x_pd_nonhot.to_numpy()\n",
    "print(train_x_nonhot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1153cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LOAD CSV WITH DATA CLEANING INSTRUCTIONS\n",
    "path = 'VariableNanDetails.csv'\n",
    "data_cleaning_inst = pd.read_csv (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b4bb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 5290)\n"
     ]
    }
   ],
   "source": [
    "#LOAD HOTENCONDED TESTING DATA TO MAKE SURE SIZE MATCHES\n",
    "dataDir = 'AnalysisData'\n",
    "dataSubDir = 'CleanDataFinal'\n",
    "\n",
    "#LOAD TESTING DATA\n",
    "#features\n",
    "path = os.path.join(dataDir, dataSubDir, 'testFeaturesFinal.csv')\n",
    "test_x_pd = pd.read_csv (path, index_col = 'HHX')\n",
    "test_x = test_x_pd.to_numpy()\n",
    "shape_wanted = test_x.shape\n",
    "print(shape_wanted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31d228",
   "metadata": {},
   "source": [
    "## REMOVE DATA RANDOMLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28892417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO REMOVE DATA RANDOMLY\n",
    "def remove_random_data(complete_data, data_percent):\n",
    "    '''replaces random entries (single features from a row) with NaN.\n",
    "    complete_data: array containing full dataset\n",
    "    data_percent: integer indicating what percent of data to remove\n",
    "    returns: array containing dataset with missing data (NaNs)'''\n",
    "    #make copy of array \n",
    "    full_data = np.copy(complete_data)\n",
    "    original_shape = full_data.shape\n",
    "    #flatten data\n",
    "    full_data = full_data.flatten()\n",
    "    #make array for incomplete data\n",
    "    inc_data = np.copy(full_data)\n",
    "\n",
    "    #calculate number of entries to replace\n",
    "    entries_to_remove = int(full_data.size*data_percent/100)\n",
    "\n",
    "    #choose random indeces of data to replace\n",
    "    i = np.random.choice(full_data.shape[0], entries_to_remove, replace=False)\n",
    "    #replace random data\n",
    "    for index in i:\n",
    "        inc_data[index] = np.nan\n",
    "    #reshape data back to original shape\n",
    "    inc_data = np.reshape(inc_data, original_shape)\n",
    "    return(inc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eeb081",
   "metadata": {},
   "source": [
    "## DATA IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca6f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 505)\n",
      "(5556, 505)\n"
     ]
    }
   ],
   "source": [
    "#remove 15% of data\n",
    "data_percent = 0\n",
    "test_x_inc = remove_random_data(test_x_nonhot, data_percent)\n",
    "#turn to dataframe\n",
    "test_x_inc_pd = pd.DataFrame(test_x_inc, columns=test_x_pd_nonhot.columns, index=test_x_pd_nonhot.index)\n",
    "print(original_shape)\n",
    "print(test_x_inc_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47c8644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 4)\n",
      "(5556, 501)\n"
     ]
    }
   ],
   "source": [
    "#ISOLATE NUMERICAL AND CATEGORICAL FEATURES\n",
    "#numerical features\n",
    "col_num = data_cleaning_inst.COLUMN_NAME[\n",
    "    (data_cleaning_inst.DATA_TYPE=='numerical') & (data_cleaning_inst.NANs != 'drop_col')]\n",
    "data_num = test_x_inc_pd.loc[:, col_num]\n",
    "print(data_num.shape)\n",
    "#categorical features\n",
    "data_cat = test_x_inc_pd.drop(columns=col_num)\n",
    "print(data_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8487675",
   "metadata": {},
   "source": [
    "## UNIVARIATE IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beba95a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5556, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NUMERICAL DATA\n",
    "#turn to array\n",
    "data_num_array = data_num.to_numpy()\n",
    "#create imputer object\n",
    "num_imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#fit simple imputer\n",
    "num_imp.fit(data_num_array)\n",
    "#impute missing data\n",
    "data_num_imp = num_imp.transform(data_num_array)\n",
    "#turn to dataframe\n",
    "data_num_imp = pd.DataFrame(data_num_imp, columns=data_num.columns, index=test_x_pd_nonhot.index)\n",
    "data_num_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359a8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 501)\n",
      "(5556, 501)\n"
     ]
    }
   ],
   "source": [
    "#CATEGORICAL DATA\n",
    "#turn to array\n",
    "data_cat_array = data_cat.to_numpy()\n",
    "#create imputer object\n",
    "cat_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "#fit simple imputer\n",
    "cat_imp.fit(data_cat_array)\n",
    "#impute missing data\n",
    "data_cat_imp = cat_imp.transform(data_cat_array)\n",
    "#turn to dataframe\n",
    "data_cat_imp = pd.DataFrame(data_cat_imp, columns=data_cat.columns, index=test_x_pd_nonhot.index)\n",
    "print(data_cat.shape)\n",
    "print(data_cat_imp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95417b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22222, 501)\n",
      "(27778, 501)\n"
     ]
    }
   ],
   "source": [
    "#JOIN WITH TRAINING DATA TO GET NUMBER OF CATEGORIES TO WORK OUT FOR ONE-HOT ENCODING\n",
    "\n",
    "#drop num columns from training data\n",
    "col_num = data_cleaning_inst.COLUMN_NAME[\n",
    "    (data_cleaning_inst.DATA_TYPE=='numerical') & (data_cleaning_inst.NANs != 'drop_col')]\n",
    "data_cat_train = train_x_pd_nonhot.drop(columns=col_num)\n",
    "print(data_cat_train.shape)\n",
    "\n",
    "#join test and train data \n",
    "x_all = pd.concat([data_cat_train, data_cat_imp], axis=0)\n",
    "print(x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb23c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 5290)\n",
      "(5556, 5290)\n"
     ]
    }
   ],
   "source": [
    "#ONE-HOT ENCODE CATEGORICAL DATA\n",
    "#make list of columns to one-hot encode\n",
    "cols = data_cleaning_inst.COLUMN_NAME[(data_cleaning_inst.ENCODING == 'one_hot') & \n",
    "                                      (data_cleaning_inst.COLUMN_NAME != 'PHQCAT_A')].tolist()\n",
    "#isolate data to encode as one-hot\n",
    "clean_onehot_data = x_all.loc[:, cols]\n",
    "nonhot_cat = data_cat_imp.drop(columns=cols)\n",
    "#create object\n",
    "enc = OneHotEncoder()\n",
    "#fit encoder\n",
    "enc.fit(clean_onehot_data)\n",
    "#transform data\n",
    "clean_onehot_data_enc = enc.transform(clean_onehot_data).toarray()\n",
    "\n",
    "#get name of new columns\n",
    "onehot_features = enc.get_feature_names_out(cols)\n",
    "#turn to df\n",
    "onehot_df = pd.DataFrame(clean_onehot_data_enc, columns = onehot_features, index=x_all.index)\n",
    "#drop training data\n",
    "test_HHX = test_x_pd_nonhot.index\n",
    "onehot_df = onehot_df.loc[test_HHX, :]\n",
    "\n",
    "#join with previous data \n",
    "test_x_imp = pd.concat([data_num_imp, onehot_df, nonhot_cat], axis=1)\n",
    "print(test_x_imp.shape)\n",
    "print(shape_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83146711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STORE DATA\n",
    "\n",
    "#make directory \n",
    "dataDir = 'ImputedData'\n",
    "if not os.path.exists(dataDir):\n",
    "    os.mkdir(dataDir)\n",
    "\n",
    "#store imputed testing data\n",
    "filepath = os.path.join(dataDir, 'SimpleImputedFeatures_02.csv')\n",
    "test_x_imp.to_csv(filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06371486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearningUVM] *",
   "language": "python",
   "name": "conda-env-MachineLearningUVM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
